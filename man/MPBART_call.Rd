% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MPBART_call.R
\name{MPBART_call}
\alias{MPBART_call}
\title{Multinomial Probit Bayesian Additive Regression Trees}
\usage{
MPBART_call(formula, data, base = NULL, test.data = NULL, varying = NULL,
  sep = ".", Prior = NULL, Mcmc = NULL, diagnostics = TRUE)
}
\arguments{
\item{formula}{response ~ demographic covariates. Demographic covariates are the covariates that are not specific to levels of the multinomial response,}

\item{data}{Training Data in wide format (for details on wide format, see documentation in R package \pkg{mlogit}). Names of alternative specific covariates (the covariates that are specific to levels of the multinomial response) should in the format of “Xa.y”, where Xa is a variable name, and y is a level of the multinomial response, and “.” is the separator. For examle, if “price” is an alternative specific covariate, and the response takes values 2, 3, and 4, then the train.data should contain “price.2”, “price.3”, and “price.4”,}

\item{base}{order index of the reference level of the multinomial response. For example, if the response takes values 2, 3, and 4, then base = 2 sets response value 3 as the reference. Default is the highest class,}

\item{test.data}{Test Data in wide format, typically without the response,}

\item{varying}{The indeces of the variables in the train.data that are alternative specific. The length of varying should be a multiple of the number of levels in the multinomial response,}

\item{sep}{The seperator of the variable name and the alternative level in the alternative specific covariates. The default separator is dot (.).}

\item{Prior}{List of Priors for MPBART: e.g., Prior = list(nu=p+2,  V= diag(p - 1), ntrees=200,  kfac=2.0, pswap=0,  pbd=1.0, pb=0.5 , beta = 2.0, alpha = 0.95, nc = 100, minobsnode = 10).
The components of Prior are
\itemize{
\item nu : The covariance matrix of latent variables is assumed to have prior distribution Inv-Wish(nu, V). nu is the degree of freedom and nu > (nlatent - 1).
\item V : The positive definite scale matrix in the Inverse-Wishart prior of the covariance matrix.
\item ntrees : The total number of trees in each round of BART fitting.
\item kfac : A tuning parameter that satisfies mu - kfac * sigma = ymin and mu + kfac * sigma = ymax, where mu and sigma are the mean and std of the Gaussian prior distribution of the sum of fit of all trees.
\item pswap : The prior probability of swap move in simulating trees; default 0, there should be pswap no larger than 1-pbd.
\item pbd : The prior probability of birth/death move in simulating trees; default 1.
\item pb : The prior probability of birth given birth/death; default 0.5.
\item alpha : The prior probability of a bottom node splits is alpha/(1+d)^beta, d is depth of node.
\item beta : see alpha.
\item nc : The number of equally spaced cutpoints between min and max for each covariate.
\item minobsnode : The minimum number of observations in bottom nodes for birth in simulating trees.
}}

\item{Mcmc}{List of MCMC starting values, burn-in ...: e.g.,     list(sigma0 = diag(p - 1), burn = 100, ndraws = 1000, nSigDr = 50, keep_sigma_draws=FALSE)
The components of Mcmc are
\itemize{
\item sigma0 : The starting value of the covariance matrix of latent variables.
\item nSigDr: User-specified upper limit to repeated draws of the covariance variance matrix of latent variables in each round of posterior draw when condition 10 in Jiao and van Dyk 2015 is not satisfied. Default 50.
}}

\item{diagnostics}{Returns convergence diagnostics and variable inclusion proportions if True (default),}
}
\value{
samp_train ndraws x n posterior matrix of the training data outcome,

samp_test ndraws x testn posterior matrix of the test data outcome,

sigmasample posterior samples of the latent variable covariance matrix,

Percent_Acceptance Percent acceptance of Metropolis-Hastings proposals across the ntrees number of trees for each posterior draw after burn-in,

Tree_Num_Nodes Average number of tree nodes across the ntrees number of trees for each posterior draw after burn-in,

Tree_Num_Leaves Average number of leaves across the ntrees number of trees for each posterior draw after burn-in,

Tree_Depth Average tree depth across the ntrees number of trees for each posterior draw after burn-in,

Inclusion_Proportions Predictor inclusion frequencies. Smaller value of ntrees (such as 10, 20, 50, 100) is recommended for the purposes of variable selection.
}
\description{
Multinomial probit modeling using Bayesian Additive Regression Trees,
}
\examples{
##simulate data (example from Friedman MARS paper)
f = function(x){
 10*sin(pi*x[,1]*x[,2]) + 20*(x[,3]-.5)^2+10*x[,4]+5*x[,5]
}
sigma = 1.0 #y = f(x) + sigma*z , z~N(0,1)
n = 100 #number of observations
set.seed(99)
x=matrix(runif(n*10),n,10) #10 variables, only first 5 matter
Ey = f(x)
u=Ey+sigma*rnorm(n)
z = (u-min(u))/(max(u)-min(u))
y = 1*(z<0.4)+ 2*(z>=0.4 & z<0.6) + 3*(z>=0.6)
p = 3 # number of outcome categories
dat = data.frame(x,y)
fml = as.formula("y ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10")
bmpfit = MPBART_call(fml, data = dat, test.data = NULL,
                    Prior = list(nu = p-1+3, V = diag(p-1),
                                 ntrees = 100,
                                 kfac = 2,
                                 pswap = 0.1, pbd = 0.5, pb = 0.25,
                                 alpha = 0.95, beta = 2.0,
                                 nc = 100, minobsnode = 10),
                    Mcmc = list(sigma0 = diag(p-1), burn = 100, ndraws = 1000,
                                nSigDr = 20, keep_sigma_draws=T))

}
