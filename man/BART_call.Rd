% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BART_call.R
\name{BART_call}
\alias{BART_call}
\title{Bayesian Additive Regression Trees}
\usage{
BART_call(formula, data, test.data = NULL, Prior = NULL, Mcmc = NULL,
  diagnostics = TRUE)
}
\arguments{
\item{formula}{response ~ covariates,}

\item{data}{Training Data with the response,}

\item{test.data}{Test Data, typically without the response,}

\item{Prior}{List of Priors for MPBART: e.g., Prior = list(nu=3,sigq=0.9, ntrees=200,  kfac=2.0, pswap=0,  pbd=1.0, pb=0.5 , beta = 2.0, alpha = 0.95, nc = 100, minobsnode = 10).
The components of Prior are
\itemize{
\item nu: The degree of freedom in the inverse chi-square prior distribution of the error variance.
\item sigq: The quantile of the error variance prior that the rough estimate (from linear regression) is placed at.
\item ntrees : The total number of trees in each round of BART fitting.
\item kfac : A tuning parameter that satisfies mu - kfac * sigma = ymin and mu + kfac * sigma = ymax, where mu and sigma are the mean and std of the Gaussian prior distribution of the sum of fit of all trees.
\item pswap : The prior probability of swap move in simulating trees; default 0, there should be pswap no larger than 1-pbd.
\item pbd : The prior probability of birth/death move in simulating trees; default 1.
\item pb : The prior probability of birth given birth/death; default 0.5.
\item alpha : The prior probability of a bottom node splits is alpha/(1+d)^beta, d is depth of node.
\item beta : see alpha.
\item nc : The number of equally spaced cutpoints between min and max for each covariate.
\item minobsnode : The minimum number of observations in bottom nodes for birth in simulating trees.
}}

\item{Mcmc}{List of MCMC starting values, burn-in ...: e.g.,     list(burn = 100, ndraws = 1000)}

\item{diagnostics}{Returns convergence diagnostics and variable inclusion proportions if True (default),}
}
\value{
treefit_train ndraws x n posterior matrix of the training data sum of trees fit,

treefit_test ndraws x testn posterior matrix of the test data sum of trees fit,

samp_train ndraws x n posterior matrix of the training data outcome,

samp_test ndraws x testn posterior matrix of the test data outcome,

sigmasample posterior samples of the error standard deviation.

Percent_Acceptance Percent acceptance of Metropolis-Hastings proposals across the ntrees number of trees for each posterior draw after burn-in,

Tree_Num_Nodes Average number of tree nodes across the ntrees number of trees for each posterior draw after burn-in,

Tree_Num_Leaves Average number of leaves across the ntrees number of trees for each posterior draw after burn-in,

Tree_Depth Average tree depth across the ntrees number of trees for each posterior draw after burn-in,

Inclusion_Proportions Predictor inclusion frequencies. Smaller value of ntrees (such as 10, 20, 50, 100) is recommended for the purposes of variable selection.
}
\description{
Bayesian Additive Regression Trees Modeling for Continuous Outcome,
}
\examples{
##simulate data (example from Friedman MARS paper)
f = function(x){
 10*sin(pi*x[,1]*x[,2]) + 20*(x[,3]-.5)^2+10*x[,4]+5*x[,5]
}
sigma = 1.0 #y = f(x) + sigma*z , z~N(0,1)
n = 100 #number of observations
set.seed(99)
x=matrix(runif(n*10),n,10) #10 variables, only first 5 matter
Ey = f(x)
y=Ey+sigma*rnorm(n)
dat = data.frame(x,y)
fml = as.formula("y ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10")
bfit = BART_call(fml, data = dat, test.data = NULL,
                Prior = list(nu = 3, sigq = 0.9,
                             ntrees = 100,
                             kfac = 2,
                             pswap = 0.1, pbd = 0.5, pb = 0.25,
                             alpha = 0.95, beta = 2.0,
                             nc = 100, minobsnode = 10),
                Mcmc = list(burn=100, ndraws = 1000))

}
